---
layout: page
title: Profile
---

Moataz Alghamdi works at the intersection of mathematics, scientific computing, and machine learning, building tools that make complex systems tractable, high-performance, and transparent. He earned a PhD in Applied Mathematics and Computational Sciences from King Abdullah University of Science and Technology (KAUST) under the supervision of Prof. Daniele Boffi. He also holds a BSc in Physics (minor in Mathematics) from the University of Washington-Seattle

In his research, Dr. Alghamdi tackles high-dimensional and uncertain systems by developing efficient surrogates that replace costly full-scale models. Using techniques like adaptive sampling, probabilistic modeling, and low-rank approximations (such as tensor-train decompositions), he makes advanced analyses feasible, enabling thorough design exploration, reliable uncertainty quantification, and informed long-term decisions in engineering, scientific computing, finance, and economics.

Looking forward, his aim is to translate advanced mathematical theory into explainable, practical systems with sustained impact across disciplines.

---
# Research Outline  


### 1. Probabilistic Modeling and Machine Learning
Probabilistic modeling and kernel methods for uncertainty-aware prediction and inference. Gaussian-process priors on function spaces (viewed through the reproducing-kernel Hilbert space lens) treat the kernel as the unifying object linking GPs, graphical/state-space models, and wide-network/linearized neural predictors. Emphasis on scalable inference via sparse/Markov and state-space representations, with attention to calibration, robustness to distribution shift, and interpretability.

### 2. Decision Making in Finance and Economics
Sequential decision making under uncertainty grounded in dynamic programming, stochastic control, and robust optimization, with emphasis on value functions, policy approximation, and risk-sensitive objectives. Probabilistic uncertainty quantification informs policies for investment, forecasting, and resource allocation, with explicit attention to constraints, transparency and the ability to satisfy domain requirements such as Sharia-compliant finance.

### 3. Data Compression with Tensor Trains

Low-rank approximation is pursued via the tensor-train (TT) decomposition technique. The focus is on rank-adaptive TT factorizations with perturbation-stable cores and explicit error/complexity control (cost scaling essentially linearly in dimension for bounded ranks). These TT surrogates compress discretized PDE operators and GP covariances, enabling scalable simulation, inference, and uncertainty quantification, and integrate naturally with kernel and probabilistic models.

### 4. Simplifying Complex Mathematical Models
Focus on parametric PDEs with high-dimensional parameter spaces, formulated at the level of the solution operator and associated spectral maps. Develop certified reduced models that balance fidelity and cost via parameter-aware adaptive sampling and rigorous a posteriori control, while treating spectral structure (eigenvalue branches and eigenspaces) as a primary output for stable mode tracking and provable complexity/accuracy guarantees.

---
# Publications & Manuscripts

### Published
- **On the Matching of Eigensolutions to Parametric PDEs**  
  *M. Alghamdi, F. Bertrand, D. Boffi, F. Bonizzoni, A. Halim, G. Priyadarshi*.  
  Presented at the **ECCOMAS Congress, Oslo (2022)**.  
  Introduced a methodology for reliably pairing eigensolutions arising in parametric PDEs, providing a framework for tracking spectral changes under parameter variations.
  
- **A Greedy Model Order Reduction Method for Parametric Elliptic PDEs**  
  *M. Alghamdi, D. Boffi, F. Bonizzoni*.  
  Submitted to *Journal of Computational and Applied Mathematics*.  
  Develops a certified greedy algorithm for efficiently constructing reduced-order models in high-dimensional parameter domains, with explicit error estimates and complexity guarantees.  

- **Data-Driven Method for Parametric PDE Eigenvalue Problems Using Gaussian Processes**  
  *M. Alghamdi, F. Bertrand, D. Boffi, A. Halim*.  
  Submitted to *Computational Methods in Applied Mathematics*.  
  Proposes a GP-based surrogate modeling framework to approximate eigenvalue trajectories in parametric PDEs, improving accuracy in non-affine, irregular parameter regimes.  

### In Preparation / Ongoing Work
- **Robust and Efficient Tracking of Eigensolutions in High-Dimensional Parameter Domains**  
  *M. Alghamdi, D. Boffi, F. Bonizzoni*. In preparation.  
  Focuses on scalable algorithms for detecting and following eigensolution branches in very high-dimensional spaces, with an emphasis on robustness against parameter irregularities.  

- **Learning-Informed Greedy Algorithms**  
  Extending certified greedy frameworks with machine learning tools (Gaussian Processes, neural networks) to automate eigensolution classification and accelerate parameter selection in complex non-affine settings.

- **Tensor-Train Methods for Parametric Eigenvalue Problems**  
  Representing families of eigenvectors in Tensor-Train (TT) format to exploit multilinear structure, combined with TT-based sampling strategies as an alternative to sparse grids. 

- **Hybrid TT + Neural Networks + Gaussian Processes**  
  Investigating how TT compression can improve the scalability of neural networks and Gaussian Processes for surrogate modeling in very high-dimensional domains. 

- **Symbolic Detection of Discrete Symmetries in Evolution Equations**  
  Developing Mathematica-based algorithms to uncover hidden symmetries in PDEs, going beyond traditional variational or Lie symmetry methods, in order to reduce modeling complexity.


---

# Conferences and Workshops

### Conferences
- ECCOMAS, Oslo (2022) â€” Contributed Talk  
- 29th Biennial Numerical Analysis Conference, Strathclyde (2023) â€” Contributed Talk  
- 28th International Conference on Domain Decomposition Methods (2024) â€” Contributed Talk  
- 7th Chilean Workshop on Numerical Analysis of PDEs (2024) â€” Contributed Talk  
- Lions-Magenes Days, Pavia (2024) â€” Poster  
- European Congress of Mathematics (ECM), Seville (2024) â€” Invited Talk

### Workshops and Schools
- NumPDE Workshop, KAUST (2025) â€” Contributed Talk  
- ICTP Summer School on Advances in Condensed Matter Physics, Samarkand (2019)
 

---
# Teaching Experience

### Teaching Experience
- **Graduate Teaching Assistant**  
  AMCS 131 (Vector Calculus & Differential Equations) and AMCS 202 (Applied Mathematics II).  
  Responsibilities included leading recitations, grading, and organizing the Winter School for students needing remediation.  

- **Mentorship**  
  Supervised Andrea Panozzo, whose Masterâ€™s thesis was partially based on my PhD research.  

- **Instructor â€” Applied Mathematics School (AMS 2023)**  
  Taught short courses and received the **Best Teacher Award** for outstanding instruction.  

# Honors and Scholarships
- **KAUST Gifted Student Program Scholarship (KGSP)**  
  Prestigious full-ride undergraduate scholarship awarded by KAUST, supporting academic excellence abroad.  

- **Saudi Arabia Cultural Mission Scholarship**  
  Full-ride scholarship covering tuition and expenses during studies at the University of Washington.  

- **KAUST Fellowship for Graduate Studies**  
  Covers tuition and housing, in addition to providing a monthly stipend during PhD studies.


---

## Contact  

- ðŸ“§ Email: [moataz.alghamdi@kaust.edu.sa](mailto:moataz.alghamdi@kaust.edu.sa)  
- ðŸ“„ [Curriculum Vitae (last updated Spring 2025)](link)  
- ðŸ’» [GitHub](https://github.com/Moatazg/)  
- ðŸ”— [LinkedIn](https://www.linkedin.com/in/moataz-alghamdi-8761001aa/)  

